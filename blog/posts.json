[
  {
    "slug": "20260226-registry-pulse-3",
    "title": "Registry Pulse: 170 New Servers, One Publisher Brings 49",
    "tag": "Pulse",
    "date": "2026-02-26",
    "summary": "The registry jumps to 2,638 servers. A single publisher registers 49 generic utility servers in three days. Elsewhere: RStudio gets an AI bridge, Coolify gets a copilot, and a tax calculator arrives just in time for filing season.",
    "body": "<p>The largest batch since the Ansvar surge — <strong>170 new servers</strong> push the registry from 2,468 to 2,638. Zero removed. Nearly a third come from a single publisher registering generic developer utilities. The rest include an R-language bridge with 128 stars, a self-hosted PaaS copilot with 185 stars, and a US tax calculator that runs entirely offline.</p><h3>By the Numbers</h3><table><thead><tr><th>Metric</th><th>Previous</th><th>Current</th><th>Change</th></tr></thead><tbody><tr><td>Total servers</td><td>2,468</td><td>2,638</td><td>+170</td></tr><tr><td>With source repos</td><td>2,059</td><td>2,212</td><td>+153</td></tr><tr><td>With packages</td><td>1,657</td><td>1,778</td><td>+121</td></tr><tr><td>Average trust score</td><td>48.8</td><td>48.7</td><td>-0.1</td></tr><tr><td>Median trust score</td><td>52</td><td>52</td><td>—</td></tr></tbody></table><h3>Trust Distribution</h3><table><thead><tr><th>Tier</th><th>Count</th><th>Change</th></tr></thead><tbody><tr><td>High Trust (80–100)</td><td>34</td><td>—</td></tr><tr><td>Moderate Trust (60–79)</td><td>493</td><td>+11</td></tr><tr><td>Low Trust (40–59)</td><td>1,466</td><td>+125</td></tr><tr><td>Very Low Trust (20–39)</td><td>641</td><td>+34</td></tr><tr><td>Unknown/Suspicious (0–19)</td><td>4</td><td>—</td></tr></tbody></table><h3>The Bulk Publisher</h3><p><strong>ryudi84</strong> (<a href=\"publisher.html#io.github.ryudi84\">io.github.ryudi84</a>) registered 49 servers in this scan — all generic developer utilities (JSON formatter, regex tester, Base64 encoder, hash generator, CSS gradient builder, and similar). The repos were created within a three-day window (February 21–23, 2026), all carry template descriptions, and none have stars or forks. The GitHub account had been dormant since 2020 before this burst. The servers are published under the brand name \"Sovereign AI\" and accompanied by several \"awesome\" list repos created in the same window. This is the second instance of bulk-template publishing after <a href=\"blog.html#20260223-i-am-the-law\">Ansvar's 70 law servers</a> — though where Ansvar's servers contained real legislation data, these wrap commodity utilities that LLMs can typically handle natively.</p><h3>Notable New Entries</h3><ul><li><strong><a href=\"blog.html#20260226-rstudio-meets-mcp\">ClaudeR</a></strong> — an R package bridging RStudio to Claude, Codex, and Gemini via MCP. Multi-agent orchestration, plot capture, htmlwidget support. 128 stars. Score: <a href=\"publisher.html#io.github.IMNMV\">72</a>.</li><li><strong><a href=\"blog.html#20260226-coolify-copilot\">Coolify MCP</a></strong> — 38 tools for managing the Coolify self-hosted PaaS through AI assistants. Claims 85% fewer tokens than a naive implementation. 185 stars. Score: <a href=\"publisher.html#io.github.StuMason\">69</a>.</li><li><strong><a href=\"blog.html#20260226-engram-memory\">Engram</a></strong> — a three-tier memory intelligence layer claiming 80% accuracy on the LOCOMO benchmark. 10 days old. Score: <a href=\"publisher.html#io.github.tstockham96\">58</a>.</li><li><strong><a href=\"blog.html#20260226-tax-season-mcp\">IRS Taxpayer MCP</a></strong> — 39 local-only US tax calculation tools. No credentials, no network calls, no telemetry. Score: <a href=\"publisher.html#io.github.dma9527\">56</a>.</li><li><strong><a href=\"blog.html#20260226-shipswift\">ShipSwift</a></strong> — an AI-native SwiftUI component library from Singapore. 315 stars, the highest in this batch. Score: <a href=\"publisher.html#io.github.signerlabs\">57</a>.</li><li><strong><a href=\"blog.html#20260226-peac-protocol\">PEAC Protocol</a></strong> — cryptographic receipts for AI agent transactions. Apache 2.0, seven months old. Score: <a href=\"publisher.html#io.github.peacprotocol\">73</a>, the highest trust score among new entries.</li><li><strong><a href=\"blog.html#20260226-evalview\">EvalView</a></strong> — pytest-style regression testing for AI agents. Golden baseline diffing without API keys. 45 stars. Score: <a href=\"publisher.html#io.github.hidai25\">66</a>.</li></ul><h3>What to Watch</h3><ol><li><strong>Bulk publishing is becoming a pattern.</strong> Ansvar brought 70 law servers; now Sovereign AI brings 49 utility servers. The registry's lack of grouping, deduplication, or publisher-level quality signals means each batch dilutes discoverability for everyone else.</li><li><strong>The R ecosystem arrived.</strong> ClaudeR is the first serious bridge between MCP and statistical computing. Data scientists, bioinformaticians, and academic researchers now have a path in.</li><li><strong>Infrastructure tools are shipping.</strong> Coolify MCP treats the self-hosted PaaS as agent-controllable infrastructure. This is MCP moving from \"talk to APIs\" to \"manage my servers.\"</li></ol><p><em>Data sourced from the <a href=\"https://registry.modelcontextprotocol.io/\">MCP Registry</a> via <a href=\"./\">MCP Scorecard</a>. Trust scores computed from observable signals only.</em></p>",
    "publishers": [
      "io.github.ryudi84",
      "io.github.IMNMV",
      "io.github.StuMason",
      "io.github.tstockham96",
      "io.github.dma9527",
      "io.github.signerlabs",
      "io.github.peacprotocol",
      "io.github.hidai25"
    ]
  },
  {
    "slug": "20260226-rstudio-meets-mcp",
    "title": "RStudio Meets MCP: Multi-Agent Data Science in Your Live Session",
    "tag": "Spotlight",
    "date": "2026-02-26",
    "summary": "An R package connects RStudio to Claude, Codex, and Gemini via MCP — letting multiple AI agents execute code, capture plots, and read htmlwidgets in a shared live session. 128 stars and counting.",
    "body": "<p>The MCP ecosystem has been overwhelmingly JavaScript and Python. <a href=\"publisher.html#io.github.IMNMV\"><code>io.github.IMNMV/clauder</code></a> opens the door to R.</p><h3>The Server</h3><p><strong>ClaudeR</strong> is an R package that bridges RStudio to MCP-compatible AI assistants — Claude Desktop, Claude Code, Codex, Gemini CLI, and Cursor. Install the R package, run <code>uvx clauder-mcp</code>, and the AI can execute code in your live RStudio session and see the results in real-time. The README describes it as:</p><blockquote><p>\"ClaudeR is an R package that forges a direct link between RStudio and MCP configured AI assistants like Claude Code or Codex. This enables interactive coding sessions where the AI can execute code in your active RStudio environment and see the results in real-time.\"</p><cite>— <a href=\"https://github.com/IMNMV/ClaudeR\">ClaudeR README</a></cite></blockquote><p>The feature set goes well beyond basic code execution. Fifteen MCP tools cover: synchronous and asynchronous R execution (long-running jobs via <code>callr</code>), plot capture, interactive widget reading (plotly, DT, leaflet — with pagination for large outputs), active document reading and editing, file access, session history, and task tracking. Security restrictions block dangerous functions like <code>system()</code>, <code>unlink()</code>, and <code>file.remove()</code> by default.</p><h3>Multi-Agent Orchestration</h3><p>The standout feature is multi-agent support. Multiple AI agents can connect to the same R session simultaneously — or spread across separate RStudio windows. Each agent gets a unique ID on startup, and console output, log files, and execution history are all attributed per agent. From the README:</p><blockquote><p>\"On its very first tool call, each agent receives a context briefing with its own ID, any other agents active on the session, and the log file path, giving it full awareness of the shared environment without any manual setup.\"</p><cite>— <a href=\"https://github.com/IMNMV/ClaudeR\">ClaudeR README</a></cite></blockquote><p>Session discovery works through files written to <code>~/.claude_r_sessions/</code> — agents find sessions automatically with no hardcoded ports or manual configuration. One agent could be cleaning data while another builds a model on the same session, each aware of the other's presence.</p><h3>Why It Matters</h3><p>R remains the language of choice for a large segment of statisticians, bioinformaticians, epidemiologists, and academic researchers. These are people who work in RStudio daily but have had no natural path into the MCP ecosystem. ClaudeR changes that. The combination of live session access, plot capture, and htmlwidget support means an AI agent can do what a human collaborator would — run code, look at the chart, iterate. The <a href=\"https://youtu.be/KSKcuxRSZDY\">demo video</a> shows this in action.</p><p>The repo has been in development since March 2025 — nearly a year of commits, MIT-licensed, published on PyPI as <code>clauder-mcp</code>. 128 stars and 14 forks. Score: <strong>72</strong>. No flags. The highest-scoring new entry in this batch after PEAC Protocol.</p><p class=\"traceback\"><strong>Sources:</strong> IMNMV — <a href=\"https://github.com/IMNMV\">GitHub</a> · ClaudeR — <a href=\"https://github.com/IMNMV/ClaudeR\">repo</a> · <a href=\"https://youtu.be/KSKcuxRSZDY\">demo video</a> · <a href=\"https://pypi.org/project/clauder-mcp/\">PyPI</a> · <a href=\"publisher.html#io.github.IMNMV\">Scorecard: io.github.IMNMV (score 72)</a></p>",
    "publishers": [
      "io.github.IMNMV"
    ]
  },
  {
    "slug": "20260226-coolify-copilot",
    "title": "Coolify Gets a Copilot: 38 Tools, 85% Fewer Tokens",
    "tag": "Spotlight",
    "date": "2026-02-26",
    "summary": "A UK developer built an MCP server that wraps the entire Coolify self-hosted PaaS API — 38 tools for managing servers, deployments, databases, and environment variables through AI assistants. 185 stars, 37 forks.",
    "body": "<p><a href=\"https://coolify.io/\">Coolify</a> is the open-source, self-hostable alternative to Heroku, Netlify, and Vercel — used by developers who want platform-as-a-service without the platform lock-in. <a href=\"publisher.html#io.github.StuMason\"><code>io.github.StuMason/coolify</code></a> now lets you manage it through Claude.</p><h3>The Server</h3><p>Built by <strong>Stu Mason</strong> (<a href=\"https://github.com/StuMason\">GitHub</a>, Folkestone, UK), <a href=\"https://github.com/StuMason/coolify-mcp\">coolify-mcp</a> exposes 38 tools across infrastructure management, diagnostics, batch operations, servers, projects, applications, databases, services, deployments, environment variables, and documentation search. The README describes it as:</p><blockquote><p>\"The most comprehensive MCP server for Coolify — 38 optimized tools, smart diagnostics, documentation search, and batch operations for managing your self-hosted PaaS through AI assistants.\"</p><cite>— <a href=\"https://github.com/StuMason/coolify-mcp\">coolify-mcp README</a></cite></blockquote><p>The design philosophy centers on token efficiency. Rather than creating one tool per CRUD operation per resource — which would produce dozens of tools with redundant descriptions — Mason consolidated related operations into single tools with action parameters. The result:</p><blockquote><p>\"The server uses 85% fewer tokens than a naive implementation (6,600 vs 43,000) by consolidating related operations into single tools with action parameters. This prevents context window exhaustion in AI assistants.\"</p><cite>— <a href=\"https://github.com/StuMason/coolify-mcp\">coolify-mcp README</a></cite></blockquote><p>Response-level reductions are even larger: application listings go from ~170KB raw to ~4.4KB summarized (97% reduction), and service listings from ~367KB to ~1.2KB (99%). The server also supports smart lookups by domain, name, or IP — not just UUID — and returns HATEOAS-style actions suggesting what the agent can do next.</p><h3>The Platform It Wraps</h3><p>Coolify has built a passionate community of self-hosters who want the deployment experience of Vercel without sending their code or data to a third party. It handles Docker, Docker Compose, and Nixpacks deployments across multiple servers. The MCP server covers the full surface: creating and managing projects, deploying applications, provisioning databases (8 types), managing environment variables in bulk, and searching Coolify's documentation. The use case is natural: <em>\"deploy my app to staging, check the logs, roll back if something breaks\"</em> — all through conversation.</p><p>TypeScript, MIT-licensed, published on npm as <code>@masonator/coolify-mcp</code>. Created March 2025, actively maintained. 185 stars, 37 forks — the forks suggest real adoption beyond curiosity. Score: <strong>69</strong>. No flags.</p><p class=\"traceback\"><strong>Sources:</strong> Stu Mason — <a href=\"https://github.com/StuMason\">GitHub</a> · coolify-mcp — <a href=\"https://github.com/StuMason/coolify-mcp\">repo</a> · <a href=\"https://www.npmjs.com/package/@masonator/coolify-mcp\">npm</a> · Coolify — <a href=\"https://coolify.io/\">coolify.io</a> · <a href=\"publisher.html#io.github.StuMason\">Scorecard: io.github.StuMason (score 69)</a></p>",
    "publishers": [
      "io.github.StuMason"
    ]
  },
  {
    "slug": "20260226-engram-memory",
    "title": "Engram: A Memory Layer That Claims to Beat Mem0",
    "tag": "Spotlight",
    "date": "2026-02-26",
    "summary": "A new MCP memory server claims 80% accuracy on the LOCOMO benchmark — a 19.6% improvement over Mem0's published results — with three tiers of memory intelligence. Ten days old, proprietary license, bold claims.",
    "body": "<p>Memory is one of the most active categories in the MCP registry. Every week brings another server offering persistent context for AI agents. <a href=\"publisher.html#io.github.tstockham96\"><code>io.github.tstockham96/engram</code></a> enters the space with benchmark numbers and architectural ambitions that set it apart from the pack.</p><h3>The Benchmark Claim</h3><p>Engram's README puts the numbers front and center, citing results on <strong>LOCOMO</strong> — a published benchmark for evaluating agent memory systems, and the same one Mem0 used to establish their state-of-the-art claim:</p><table><thead><tr><th>System</th><th>Accuracy</th><th>Tokens/Query</th></tr></thead><tbody><tr><td><strong>Engram</strong></td><td><strong>80.0%</strong></td><td><strong>1,504</strong></td></tr><tr><td>Full Context</td><td>88.4%</td><td>23,423</td></tr><tr><td>Mem0 (published)</td><td>66.9%</td><td>—</td></tr><tr><td>MEMORY.md</td><td>28.8%</td><td>—</td></tr></tbody></table><p>Ten conversations, 1,540 questions, four categories. Engram claims a 19.6% relative improvement over Mem0 with 93.6% fewer tokens than full context. These are self-reported numbers on a 10-day-old project — worth watching, not yet independently verified.</p><h3>The Architecture</h3><p>The distinguishing design choice is what Engram calls three-tier memory intelligence:</p><blockquote><p>\"Existing memory solutions are storage layers — they save facts and retrieve them. Engram is an intelligence layer.\"</p><cite>— <a href=\"https://github.com/tstockham96/engram\">Engram README</a></cite></blockquote><p>The three tiers: <strong>Explicit Memory</strong> stores facts, preferences, and conversation turns — the standard approach. <strong>Implicit Memory</strong> detects behavioral patterns from how users work, not just what they say. <strong>Synthesized Memory</strong> runs a consolidation process that produces insights by merging related memories, resolving contradictions, and generating observations nobody explicitly asked for. The key claim: <em>\"Engram invests intelligence at read time (when the query is known), not write time (when you don't know what'll matter).\"</em></p><p>The implementation uses SQLite (no Docker, no Redis, no Neo4j), a bi-temporal model that tracks when facts were true versus when they were stored, and spreading activation for graph-based context surfacing. Model-agnostic — works with Gemini, OpenAI, Ollama, Groq, and Cerebras.</p><h3>What to Know</h3><p>Built by <strong>Thomas Stockham</strong>. The repo was created February 16, 2026 — ten days before this scan. It has 14 stars, zero forks, and a small number of commits. The license is proprietary (free for internal use, commercial licensing available), despite the README badge initially suggesting BSL 1.1. Pricing tiers range from free (1,000 memories, 1 agent) through enterprise. The benchmark claims are ambitious relative to the project's maturity. If the LOCOMO numbers hold up under independent evaluation, this is a meaningful contribution to the agent memory space. The architecture is thoughtful and the positioning against existing solutions is clear. Time will tell whether the claims match reality at scale.</p><p>Score: <strong>58</strong>. No flags.</p><p class=\"traceback\"><strong>Sources:</strong> Thomas Stockham — <a href=\"https://github.com/tstockham96\">GitHub</a> · Engram — <a href=\"https://github.com/tstockham96/engram\">repo</a> · LOCOMO benchmark — referenced in README · <a href=\"publisher.html#io.github.tstockham96\">Scorecard: io.github.tstockham96 (score 58)</a></p>",
    "publishers": [
      "io.github.tstockham96"
    ]
  },
  {
    "slug": "20260226-tax-season-mcp",
    "title": "Tax Season Gets an MCP Server",
    "tag": "Spotlight",
    "date": "2026-02-26",
    "summary": "39 tools for US individual tax calculations — federal brackets, state taxes for all 50 states, retirement strategies, and OBBB Act provisions. Everything runs locally. No credentials, no network calls, no telemetry.",
    "body": "<p>Tax season is here, and someone built an MCP server for it. <a href=\"publisher.html#io.github.dma9527\"><code>io.github.dma9527/irs-taxpayer</code></a> provides 39 tools covering US individual tax calculations — and its defining feature is that none of them phone home.</p><h3>The Server</h3><p>The <a href=\"https://github.com/dma9527/irs-taxpayer-mcp\">irs-taxpayer-mcp</a> README describes it as:</p><blockquote><p>\"The most thorough open-source tax assistant for US individual taxpayers — powered by Model Context Protocol.\"</p><cite>— <a href=\"https://github.com/dma9527/irs-taxpayer-mcp\">irs-taxpayer-mcp README</a></cite></blockquote><p>The scope is broad: federal tax calculations with bracket breakdowns, AMT, NIIT (3.8%), and Additional Medicare Tax (0.9%). Standard vs. itemized deduction analysis with year-specific SALT caps ($10K for TY2024, $40K for TY2025 under the One Big Beautiful Bill Act). Over 20 tax credits including EITC with phase-in/plateau/phase-out curves, Child Tax Credit, AOTC, EV credits, and solar. Retirement strategies: Backdoor Roth, Mega Backdoor, Roth Conversion Ladder, optimal withdrawal order, RMD calculations. State taxes for all 50 states plus DC, with side-by-side comparison. Capital gains optimization with lot analysis, 0% bracket harvesting, and wash sale warnings. Quarterly estimates with safe harbor rules. Audit risk assessment.</p><p>The OBBB Act coverage is a notable detail — it includes the new deductions for tips ($25K), overtime ($12.5K), senior bonus ($6K for age 65+), and auto loan interest ($10K) that most tax software hasn't yet incorporated.</p><h3>The Privacy Architecture</h3><p>Every calculation runs locally. The privacy model from the README:</p><table><thead><tr><th>Layer</th><th>Design</th></tr></thead><tbody><tr><td>All tax calculations</td><td>100% local execution — zero network calls</td></tr><tr><td>User data storage</td><td>Stateless — nothing saved between calls</td></tr><tr><td>Authentication</td><td>Zero credentials — no SSN, no IRS login</td></tr><tr><td>Remote data</td><td>Only public IRS info (form descriptions, deadlines)</td></tr><tr><td>Telemetry</td><td>None — no analytics, no tracking, no logging</td></tr><tr><td>Source code</td><td>Fully open-source (MIT) — audit every calculation</td></tr></tbody></table><p>This matters for tax data. People are understandably reluctant to send their income, deductions, and filing status to a cloud service. A stateless, offline tax calculator that an AI agent can invoke locally is a meaningfully different trust model than a web-based tax prep tool.</p><h3>What to Know</h3><p>Built by an anonymous developer (GitHub: <a href=\"https://github.com/dma9527\">dma9527</a>). Created February 17, 2026 — nine days before this scan. TypeScript, MIT-licensed, published on npm. The README is available in four languages (English, Chinese, Spanish, Japanese). Zero stars, zero forks — very new. The standard disclaimer applies: this is not tax advice, and the accuracy of the calculations depends on the implementation correctly reflecting IRS rules. The source is open for audit, which is the right approach for a tool like this.</p><p>Score: <strong>56</strong>. No flags.</p><p class=\"traceback\"><strong>Sources:</strong> dma9527 — <a href=\"https://github.com/dma9527\">GitHub</a> · irs-taxpayer-mcp — <a href=\"https://github.com/dma9527/irs-taxpayer-mcp\">repo</a> · <a href=\"publisher.html#io.github.dma9527\">Scorecard: io.github.dma9527 (score 56)</a></p>",
    "publishers": [
      "io.github.dma9527"
    ]
  },
  {
    "slug": "20260226-shipswift",
    "title": "ShipSwift: An AI-Native SwiftUI Library with 315 Stars",
    "tag": "Spotlight",
    "date": "2026-02-26",
    "summary": "A Singapore company built a SwiftUI component library designed from the ground up to be consumed by LLMs. The MCP server delivers recipes — implementation guides that AI agents use to build iOS apps. 315 stars, the highest in this batch.",
    "body": "<p>Most MCP servers connect AI to existing APIs or services. <a href=\"publisher.html#io.github.signerlabs\"><code>io.github.signerlabs/shipswift</code></a> takes a different approach: it's a component library built to be consumed by AI agents, with MCP as the delivery mechanism.</p><h3>The Server</h3><p><strong>ShipSwift</strong>, from <a href=\"https://github.com/signerlabs\">Signer Labs</a> (Singapore), describes itself as:</p><blockquote><p>\"AI-native SwiftUI component library — production-ready code that LLMs can use to build real apps.\"</p><cite>— <a href=\"https://github.com/signerlabs/ShipSwift\">ShipSwift README</a></cite></blockquote><p>The MCP integration provides three tools: <code>listRecipes</code>, <code>getRecipe</code>, and <code>searchRecipes</code>. Each recipe is an implementation guide — not just a code snippet, but a structured document an AI agent can follow to build a feature. The library itself contains SwiftUI components across animations (BeforeAfterSlider, TypewriterText, ShakingIcon, Shimmer, and more), charts (line, bar, area, donut, ring, radar, scatter, activity heatmap), display components, input controls, and full multi-file modules including authentication (Amplify/Cognito), camera (with Vision face detection), paywall (StoreKit 2), chat (with voice ASR), and settings.</p><p>The open-source/pro split is clear: all iOS client code is MIT-licensed. Pro recipes add backend implementations, compliance templates, and production deployment guidance. A hosted MCP endpoint at <code>api.shipswift.app/mcp</code> provides access alongside the standard Claude Code Skills integration.</p><h3>Why It's Interesting</h3><p>The \"AI-native\" framing is the interesting bet here. Instead of wrapping an existing human-facing API, ShipSwift designed its components with LLM consumption as a first-class use case. The structured recipe format gives agents more context than raw documentation — what to import, how components compose, what edge cases to handle. Whether this produces measurably better results than an agent reading standard SwiftUI documentation is an open question, but the approach represents a thoughtful hypothesis about how code libraries should be packaged for the agent era.</p><p>With 315 stars and 27 forks, ShipSwift has the highest star count of any new entry in this batch. The iOS/SwiftUI angle is also distinctive — the MCP registry is heavily weighted toward web and backend tooling, and native mobile development remains underserved.</p><p>Score: <strong>57</strong>. No flags. The relatively low score despite high star count reflects the absence of a published package in the registry and a lower provenance score.</p><p class=\"traceback\"><strong>Sources:</strong> Signer Labs — <a href=\"https://github.com/signerlabs\">GitHub</a> · ShipSwift — <a href=\"https://github.com/signerlabs/ShipSwift\">repo</a> · <a href=\"https://shipswift.app\">shipswift.app</a> · <a href=\"publisher.html#io.github.signerlabs\">Scorecard: io.github.signerlabs (score 57)</a></p>",
    "publishers": [
      "io.github.signerlabs"
    ]
  },
  {
    "slug": "20260226-peac-protocol",
    "title": "Cryptographic Receipts for AI Agent Transactions",
    "tag": "Spotlight",
    "date": "2026-02-26",
    "summary": "PEAC Protocol standardizes verifiable interaction records for AI agents operating across organizational boundaries — a discoverable policy file, a signed receipt format, and a portable evidence bundle for offline verification. Score: 73.",
    "body": "<p>As AI agents begin conducting transactions across organizational boundaries, a quiet question emerges: how do you prove what happened? <a href=\"publisher.html#io.github.peacprotocol\"><code>io.github.peacprotocol/peac</code></a> proposes an answer.</p><h3>The Protocol</h3><p><strong>PEAC</strong> — Portable Evidence for Agent Coordination — standardizes three artifacts:</p><blockquote><p>\"A discoverable policy file (<code>/.well-known/peac.txt</code>), a signed receipt format (<code>peac-receipt/0.1</code> JWS), and a portable evidence bundle for offline verification.\"</p><cite>— <a href=\"https://github.com/peacprotocol/peac\">PEAC README</a></cite></blockquote><p>The problem it addresses:</p><blockquote><p>\"AI agents and automated systems operate across organizational boundaries, but proof of what happened stays locked in internal logs. When billing errors, policy violations, or safety incidents arise, there's no neutral, portable evidence that both parties can verify.\"</p><cite>— <a href=\"https://github.com/peacprotocol/peac\">PEAC README</a></cite></blockquote><p>The flow: a service publishes a policy file at <code>/.well-known/peac.txt</code> (YAML with usage terms, purposes, rate limits). An agent makes a request and receives a signed receipt as a <code>PEAC-Receipt</code> HTTP header — an Ed25519 JWS that can be verified offline using the issuer's public keys at <code>/.well-known/peac-issuer.json</code>. For disputes, a portable evidence bundle (ZIP) packages receipts, policies, and verification reports for offline audit. Replay protection via nonce and timestamp, fail-closed design, SSRF guards.</p><h3>Where It Fits</h3><p>PEAC explicitly complements — rather than replaces — existing infrastructure. OpenTelemetry handles observability. MCP and A2A handle tool coordination. Payment rails handle money movement. PEAC sits underneath as the evidence layer: <em>what terms applied, what happened, and here's the cryptographic proof</em>. The spec includes an x402 adapter for machine payments, suggesting the authors are thinking about the intersection of agent commerce and verifiable receipts.</p><p>Reference implementations exist in TypeScript and Go, plus an MCP server with five tools and Express middleware for easy integration. The project is stewarded by <a href=\"https://www.originary.xyz/\">Originary</a> and the open-source community.</p><h3>What to Know</h3><p>The repo was created July 2025 — seven months of development, which gives it more maturity than most new entries. Apache 2.0 licensed, 10 stars, 4 forks. The concept is forward-looking: there isn't yet a critical mass of autonomous agent-to-agent commerce to generate urgent demand for verifiable receipts. But the spec is well-documented, the architecture is sound, and if agent transactions become routine, having a receipt standard in place before the disputes start is better than scrambling after.</p><p>Score: <strong>73</strong> — the highest trust score among new entries in this batch, driven by strong provenance (85) and maintenance (71) signals.</p><p class=\"traceback\"><strong>Sources:</strong> PEAC Protocol — <a href=\"https://github.com/peacprotocol\">GitHub org</a> · <a href=\"https://github.com/peacprotocol/peac\">repo</a> · <a href=\"https://www.peacprotocol.org\">peacprotocol.org</a> · Originary — <a href=\"https://www.originary.xyz/\">originary.xyz</a> · <a href=\"publisher.html#io.github.peacprotocol\">Scorecard: io.github.peacprotocol (score 73)</a></p>",
    "publishers": [
      "io.github.peacprotocol"
    ]
  },
  {
    "slug": "20260226-evalview",
    "title": "EvalView: pytest for AI Agents",
    "tag": "Spotlight",
    "date": "2026-02-26",
    "summary": "A Harvard Extension School graduate in Tel Aviv built a regression testing framework for AI agents — golden baseline diffing that catches behavioral drift after prompt changes, model swaps, or tool updates. 45 stars, no API keys required.",
    "body": "<p>Observability platforms show you what your AI agent did. Eval platforms score how well it did. <a href=\"publisher.html#io.github.hidai25\"><code>io.github.hidai25/evalview-mcp</code></a> answers a different question: <em>did my agent break?</em></p><h3>The Server</h3><p><strong>EvalView</strong>, built by <strong>Hidai Bar-Mor</strong> (<a href=\"https://github.com/hidai25\">GitHub</a>, Tel Aviv), is a pytest-style testing framework for AI agents. The README frames the positioning directly:</p><blockquote><p>\"Unlike observability platforms (LangSmith) that show you what happened, or eval platforms (Braintrust) that score how good your agent is, EvalView answers: 'Did my agent break?'\"</p><cite>— <a href=\"https://github.com/hidai25/eval-view\">EvalView README</a></cite></blockquote><p>The core workflow: save a golden baseline of your agent's behavior, then run checks after any change — prompt edits, model swaps, tool updates. EvalView diffs the results and reports one of four statuses: PASSED (behavior matches), TOOLS_CHANGED (different tools called), OUTPUT_CHANGED (same tools, different output quality), or REGRESSION (significant score drop). Deterministic tool-call and sequence scoring means no LLM-as-judge dependency for basic checks, though a statistical mode with LLM judge caching is available for deeper evaluation.</p><h3>Features</h3><p>The tool set is broader than basic diffing: framework-native adapters for LangGraph, CrewAI, OpenAI Assistants, Anthropic Claude, HuggingFace, and Ollama. Forbidden tool contracts — declare tools that must never be called, and the test hard-fails immediately. HTML trace replay for forensic debugging with full prompt/completion spans. Multi-reference goldens (up to five variants) for non-deterministic agents. CI/CD integration with a GitHub Action, exit codes, PR comments, and JSON output. Eight MCP tools including test creation, snapshot runs, skill validation, and visual report generation.</p><h3>The Builder</h3><p>Bar-Mor describes himself as a finance professional and software engineering master's graduate from Harvard Extension School. His GitHub history spans several years of projects — from Harvard coursework (web development, data science) to a Chrome extension using GPT-3, a Unity fighting game, and household management apps. EvalView represents a more focused bet on AI agent infrastructure.</p><p>The repo was created November 2025, Python, Apache 2.0 licensed, published on PyPI as <code>evalview</code>. 45 stars, 5 forks. The MCP integration provides agent-level access to the testing workflow, but the core value is the testing framework itself — this is a developer tool that happens to also be an MCP server, rather than the other way around.</p><p>Score: <strong>66</strong>. No flags.</p><p class=\"traceback\"><strong>Sources:</strong> Hidai Bar-Mor — <a href=\"https://github.com/hidai25\">GitHub</a> · EvalView — <a href=\"https://github.com/hidai25/eval-view\">repo</a> · <a href=\"https://pypi.org/project/evalview/\">PyPI</a> · <a href=\"publisher.html#io.github.hidai25\">Scorecard: io.github.hidai25 (score 66)</a></p>",
    "publishers": [
      "io.github.hidai25"
    ]
  },
  {
    "slug": "20260225-government-data-finds-mcp",
    "title": "Government Data Finds MCP",
    "tag": "Spotlight",
    "date": "2026-02-25",
    "summary": "A Canadian university student built an MCP server for Statistics Canada's open data API — and it's the highest-provenance government data server in the registry. Eight government and open-data servers now exist. The public sector is arriving.",
    "body": "<p>Most MCP servers wrap developer tools or SaaS APIs. A quieter category is forming underneath: <strong>government open data</strong>. Eight servers in the registry now expose public-sector datasets through MCP, and the one with the strongest trust signals was built by a university student in Ontario.</p><h3>The Server</h3><p><a href=\"publisher.html#io.github.Aryan-Jhaveri\"><code>io.github.Aryan-Jhaveri/mcp-statcan</code></a> connects AI agents to <strong>Statistics Canada's Web Data Service</strong> — the API behind one of the world's most comprehensive national statistical agencies. Canada publishes everything from CPI to immigration to labor force data through this API, and now an MCP server makes it conversational.</p><p>The tools are serious: cube operations (search, list, metadata, download links), vector operations (series data, bulk fetches by date range), and a SQLite persistence layer so agents can store and query retrieved data locally. The README is refreshingly honest about the limitations:</p><blockquote><p>\"LLMs tend to default to <code>get_data_from_cube_pid_coord_and_latest_n_periods</code> in a loop (one API call per data point) instead of using bulk vector tools... This is slower, wastes API calls, and increases the risk of the LLM fabricating numbers when it loses patience mid-loop.\"</p><cite>— <a href=\"https://github.com/Aryan-Jhaveri/mcp-statcan\">mcp-statcan README</a></cite></blockquote><p>The recommended pattern: bulk vector fetch, store to SQLite, then SQL queries. That's not a workaround — it's good data engineering advice that happens to also be the right way to use MCP for analytical workloads.</p><h3>The Builder</h3><p><strong>Aryan Jhaveri</strong> is a BSc student at <a href=\"https://brocku.ca/\">Brock University</a> in St. Catharines, Ontario, with interests in biomedical science, data analysis, and creative coding. His GitHub shows a pattern: three MCP servers, all wrapping Canadian public data — StatCan, <a href=\"https://github.com/Aryan-Jhaveri/mcp-foodguidecanada\">Canada's Food Guide</a>, and <a href=\"https://github.com/Aryan-Jhaveri/mcp-brockevents\">Brock University events</a>. Plus a Google Earth Engine code generator. This is someone who sees public data APIs and thinks \"this should be an agent tool.\"</p><p>The StatCan server has been in development since April 2025 — 69 commits over 10 months, recently refactored from FastMCP to the standard MCP SDK with a custom ToolRegistry. MIT-licensed, published on PyPI, zero flags. Score: <strong>63</strong>, with the highest provenance rating (80) of any government data server in the registry.</p><h3>The Landscape</h3><p>StatCan isn't alone. Eight government and open-data MCP servers now exist in the registry:</p><table><thead><tr><th>Server</th><th>Domain</th><th>Score</th></tr></thead><tbody><tr><td><a href=\"publisher.html#io.github.Aryan-Jhaveri\">StatCan</a></td><td>Canadian statistics</td><td>63</td></tr><tr><td><a href=\"publisher.html#io.github.cyanheads\">ClinicalTrials.gov</a></td><td>US clinical trials</td><td>63</td></tr><tr><td><a href=\"publisher.html#io.github.therealtimex\">UN Data Commons</a></td><td>UN statistical data</td><td>57</td></tr><tr><td><a href=\"publisher.html#io.github.stucchi\">Italy OpenData</a></td><td>Italian open data</td><td>56</td></tr><tr><td><a href=\"publisher.html#eu.ansvar\">Malaysian Law</a></td><td>Malaysian legislation</td><td>54</td></tr><tr><td><a href=\"publisher.html#io.github.Dewars30\">Fulcrum Governance</a></td><td>Governance data</td><td>42</td></tr><tr><td><a href=\"publisher.html#ai.smithery\">Google Data Commons</a></td><td>Google's data aggregation</td><td>41</td></tr><tr><td><a href=\"publisher.html#io.github.torkjacobs\">Tork Governance</a></td><td>Governance tools</td><td>39</td></tr></tbody></table><p>The pattern is global but early. Canadian statistics, American clinical trials, Italian open data, UN development indicators, Malaysian law. Each built independently, mostly by solo developers, with no coordination. Google's Data Commons MCP — wrapping their aggregation of World Bank, CDC, and Eurostat data — sits at the bottom with a score of 41 because it lacks a license and has minimal maintenance signals. The student project outscores the Google one.</p><h3>Why This Matters</h3><p>Government open data has a distribution problem. The data is public, often high-quality, and frequently ignored because the APIs are arcane, the documentation is bureaucratic, and the schemas require domain knowledge to navigate. StatCan's Web Data Service is powerful but not intuitive — cube IDs, vector IDs, coordinate strings, reference periods. An MCP server turns that into a conversation: <em>\"What was Canada's unemployment rate last quarter?\"</em></p><p>This is the same pattern that made MCP work for developer tools — take a powerful but hostile interface and put a natural language layer on top. The difference is that government data serves a broader audience. Journalists, researchers, policy analysts, students — people who need the data but shouldn't need to learn an API to get it.</p><p>Eight servers is a signal, not a movement. But the ingredients are here: public APIs with no authentication barriers, data that's explicitly meant to be accessible, and a protocol that turns technical interfaces into conversational ones. If MCP is going to matter beyond developer productivity, public-sector data is one of the most natural fits. A Canadian undergrad just showed everyone the playbook.</p><p class=\"traceback\"><strong>Sources:</strong> Aryan Jhaveri — <a href=\"https://github.com/Aryan-Jhaveri\">GitHub</a> · <a href=\"https://www.linkedin.com/in/aryanjhaveri/\">LinkedIn</a> · mcp-statcan — <a href=\"https://github.com/Aryan-Jhaveri/mcp-statcan\">repo</a> · Statistics Canada Web Data Service — <a href=\"https://www.statcan.gc.ca/en/developers/wds\">API docs</a> · <a href=\"publisher.html#io.github.Aryan-Jhaveri\">Scorecard: io.github.Aryan-Jhaveri (score 63)</a></p>",
    "publishers": [
      "io.github.Aryan-Jhaveri"
    ]
  },
  {
    "slug": "20260224-registry-pulse-2",
    "title": "Registry Pulse: Crypto Arrives, Claude Learns to DJ",
    "tag": "Pulse",
    "date": "2026-02-24",
    "summary": "11 new servers push the registry to 2,468. Three are blockchain, one live-codes music, and a $10M translation company ships closed-source. The ecosystem diversifies.",
    "body": "<p>A quieter scan this time — <strong>11 new servers</strong>, pushing the registry from 2,457 to 2,468. No bulk publishers, no template factories. Instead, a batch that says more about where MCP is headed than the numbers suggest: three blockchain servers, an AI DJ, a multi-agent deliberation platform, Canadian government data, and a $10M translation company that shipped without source code.</p><h3>By the Numbers</h3><table><thead><tr><th>Metric</th><th>Previous</th><th>Current</th><th>Change</th></tr></thead><tbody><tr><td>Total servers</td><td>2,457</td><td>2,468</td><td>+11</td></tr><tr><td>With source repos</td><td>2,049</td><td>2,059</td><td>+10</td></tr><tr><td>With packages</td><td>1,648</td><td>1,657</td><td>+9</td></tr><tr><td>Average trust score</td><td>48.8</td><td>48.8</td><td>—</td></tr><tr><td>Publishers</td><td>1,711</td><td>1,720</td><td>+9</td></tr></tbody></table><h3>Trust Distribution</h3><table><thead><tr><th>Tier</th><th>Count</th><th>Change</th></tr></thead><tbody><tr><td>High Trust (80–100)</td><td>34</td><td>—</td></tr><tr><td>Moderate Trust (60–79)</td><td>482</td><td>+2</td></tr><tr><td>Low Trust (40–59)</td><td>1,341</td><td>+7</td></tr><tr><td>Very Low Trust (20–39)</td><td>607</td><td>+2</td></tr><tr><td>Unknown/Suspicious (0–19)</td><td>4</td><td>—</td></tr></tbody></table><h3>Notable New Entries</h3><ul><li><strong><a href=\"blog.html#20260224-crypto-finds-mcp\">Three crypto servers</a></strong> in a single batch — <a href=\"publisher.html#io.github.debridge-finance\">deBridge</a> (cross-chain swaps, $5.5M funded, 25 stars), <a href=\"publisher.html#io.github.Jrigada\">foundry-zksync</a> (zkSync smart contract tooling), and <a href=\"publisher.html#io.github.douglasborthwick-crypto\">Insumer</a> (on-chain verification across 31 chains). DeFi is arriving.</li><li><strong><a href=\"blog.html#20260224-claude-learns-to-dj\">DJ Claude</a></strong> — an MCP server that live-codes music using Strudel patterns, with a retro web app at <a href=\"https://claude.dj\">claude.dj</a>. Five interaction modes including a TUI with club themes. Score: <a href=\"publisher.html#io.github.p-poss\">56</a>.</li><li><strong><a href=\"blog.html#20260225-government-data-finds-mcp\">StatCan MCP</a></strong> — Statistics Canada datasets via MCP with SQLite persistence. Government open data gets an agent interface. Score: 63, the highest in this batch.</li><li><strong><a href=\"publisher.html#io.github.kyrylopr\">LensPR</a></strong> — 60+ code intelligence tools giving AI agents dependency graph awareness before they edit. Score: 57.</li><li><strong><a href=\"publisher.html#io.github.ikoskela\">Wisepanel</a></strong> — multi-agent deliberation across Claude, Gemini, and Perplexity. An MCP server that orchestrates other AI models. Had a <a href=\"https://news.ycombinator.com/item?id=47031423\">Show HN</a>.</li><li><strong><a href=\"publisher.html#io.github.oytuntez\">MotaWord</a></strong> — a $10M-valued NYC translation platform whose CTO published an MCP server with no source code. Score: 22. Real companies, closed source.</li></ul><h3>What to Watch</h3><ol><li><strong>Crypto found MCP.</strong> Three blockchain servers in one batch isn't coincidence — DeFi protocols are treating agent interfaces as table stakes. <a href=\"blog.html#20260224-crypto-finds-mcp\">More on this below.</a></li><li><strong>The creative fringe is real.</strong> DJ Claude isn't a developer tool or a SaaS wrapper. It's someone building something genuinely weird and delightful. The registry needs more of this.</li><li><strong>Established companies are shipping closed-source.</strong> MotaWord is a real company with real revenue — and they registered an MCP server with no source repo. This will become a pattern as commercial adoption grows.</li></ol><p><em>Data sourced from the <a href=\"https://registry.modelcontextprotocol.io/\">MCP Registry</a> via <a href=\"./\">MCP Scorecard</a>. Trust scores computed from observable signals only.</em></p>",
    "publishers": [
      "io.github.debridge-finance",
      "io.github.Jrigada",
      "io.github.douglasborthwick-crypto",
      "io.github.p-poss",
      "io.github.Aryan-Jhaveri",
      "io.github.kyrylopr",
      "io.github.ikoskela",
      "io.github.oytuntez"
    ]
  },
  {
    "slug": "20260224-claude-learns-to-dj",
    "title": "Claude Learns to DJ",
    "tag": "Spotlight",
    "date": "2026-02-24",
    "summary": "An MCP server that turns Claude into a live-coding DJ, generating Strudel music patterns in real-time with a retro web interface at claude.dj.",
    "body": "<p>Most MCP servers connect AI to databases, APIs, or developer tools. <a href=\"publisher.html#io.github.p-poss\"><code>io.github.p-poss/dj-claude</code></a> connects it to a sound system.</p><p>Built by <strong>Patrick Poss</strong>, DJ Claude turns AI agents into live-coding musicians using <a href=\"https://strudel.cc/\">Strudel</a> — a browser-based music live coding environment that ports TidalCycles pattern language to JavaScript. The agent generates Strudel patterns, the server evaluates them, and music plays. In real-time. The web interface at <a href=\"https://claude.dj\">claude.dj</a> looks like it was designed by someone who misses CRT monitors — neon orange text on black, a retro boot sequence, toggles for NIGHT, DISCO, and RAVE modes, and a setting that reads <em>\"CLUB: Anthropic\"</em>.</p><p>The scope is broader than a gimmick. Five interaction modes:</p><ul><li><strong>Claude Code plugin</strong> — <code>/plugin install dj-claude</code> and Claude starts writing music in your terminal</li><li><strong>Web app</strong> — the full <a href=\"https://claude.dj\">claude.dj</a> experience with visual modes and club themes</li><li><strong>Terminal TUI</strong> — a text UI for headless music generation</li><li><strong>Headless scripting</strong> — pipe Strudel patterns programmatically</li><li><strong>MCP server</strong> — standard stdio transport for any MCP client</li></ul><p>Cross-platform too: macOS, Windows, Linux (with JACK or PipeWire-JACK for audio). An optional browser audio backend handles higher-quality output. The codebase is TypeScript, MIT-licensed, published on npm, created December 2025 — this has been cooking for two months before hitting the registry.</p><p>What makes this interesting isn't the novelty — it's the implication. Live-coded music is inherently generative and iterative. The agent writes a pattern, hears the result, adjusts. That feedback loop is closer to how creative AI workflows should work than the typical request-response pattern of most MCP integrations. If the protocol is going to matter beyond developer productivity, creative tools like this are where you'd expect to see it. DJ Claude is a proof point: MCP as a creative medium, not just a plumbing layer.</p><p>Score: 56. No flags. The repo is clean, the package is published, and the server does what it says. The only thing it's missing is an audience.</p><p class=\"traceback\"><strong>Sources:</strong> Patrick Poss — <a href=\"https://github.com/p-poss\">GitHub</a> · DJ Claude — <a href=\"https://github.com/p-poss/dj-claude\">repo</a> · <a href=\"https://claude.dj\">claude.dj</a> · Strudel — <a href=\"https://strudel.cc/\">strudel.cc</a> · <a href=\"publisher.html#io.github.p-poss\">Scorecard: io.github.p-poss (score 56)</a></p>",
    "publishers": [
      "io.github.p-poss"
    ]
  },
  {
    "slug": "20260224-crypto-finds-mcp",
    "title": "Crypto Finds MCP: Three Blockchain Servers in One Batch",
    "tag": "Trend",
    "date": "2026-02-24",
    "summary": "A $5.5M-funded cross-chain protocol, a zkSync development toolkit, and a privacy-preserving on-chain verifier all registered MCP servers in the same scan. DeFi is treating agent interfaces as infrastructure.",
    "body": "<p>Three of eleven new servers in this scan are blockchain projects. That's 27% of the batch from a sector that had almost no MCP presence a week ago. Each comes at the problem from a different angle, and together they outline how crypto is approaching agent tooling.</p><h3>deBridge: Venture-Backed Cross-Chain Swaps</h3><p><a href=\"publisher.html#io.github.debridge-finance\"><code>io.github.debridge-finance/debridge-mcp</code></a> is the heavyweight. <strong>deBridge</strong> is a cross-chain interoperability protocol that raised <a href=\"https://www.coindesk.com/business/2021/09/07/cross-chain-protocol-debridge-gets-55m-in-seed-funding-round-led-by-parafi-capital\">$5.5 million in seed funding</a> led by ParaFi Capital, with participation from Animoca Brands, Crypto.com Capital, and 40+ other investors. Co-founded by <strong>Alex Smirnov</strong>, the protocol enables cross-chain swaps and transfers across 20+ blockchains. Their MCP server lets AI agents find optimal swap routes, check fees, and initiate trades — 25 GitHub stars already, TypeScript, MIT-licensed, Docker-ready, with integration guides for Claude Code, Cursor, Windsurf, and five other MCP clients.</p><p>Score: <strong>62</strong>. No flags. This is a well-funded protocol team treating MCP as a first-class integration channel, not an afterthought.</p><h3>foundry-zksync: Smart Contract Tooling for ZK Rollups</h3><p><a href=\"publisher.html#io.github.Jrigada\"><code>io.github.Jrigada/foundry-zksync</code></a> wraps the foundry-zksync CLI — the standard development toolkit for zkSync, Ethereum's leading ZK rollup. Built by <strong>Jrigada</strong>, it exposes 21 tools for compiling, testing, deploying, and verifying smart contracts through natural language. The standout detail: a built-in knowledge base of 45+ entries covering zkSync-specific gotchas and edge cases. Security-conscious key management too — hardware wallets, cloud KMS (AWS, GCP), and encrypted keystores instead of passing private keys through MCP parameters. 133 tests.</p><p>Score: <strong>56</strong>. Created February 23, 2026 — brand new but architecturally serious.</p><h3>Insumer: Privacy-Preserving On-Chain Verification</h3><p><a href=\"publisher.html#io.github.douglasborthwick-crypto\"><code>io.github.douglasborthwick-crypto/insumer</code></a> takes a different angle entirely. Instead of trading or deploying, Insumer lets AI agents <em>verify</em> on-chain conditions — token balances, NFT ownership, multi-chain logic — across 31 blockchains (30 EVM + Solana) without exposing wallet balances or private data. ECDSA-signed attestation results. A credit system (1 USDC = 25 credits) and a merchant onboarding flow suggest this is aimed at commerce: prove you hold the token, get the discount, skip the KYC.</p><p>Score: <strong>51</strong>. JavaScript, MIT-licensed, newly registered.</p><h3>The Pattern</h3><p>What connects these three isn't just blockchain — it's the bet that AI agents will become primary interfaces for on-chain operations. deBridge wants agents to route trades. foundry-zksync wants agents to deploy contracts. Insumer wants agents to verify holdings. Each is building for a world where the human doesn't interact with the blockchain directly — the agent does, through MCP.</p><p>This mirrors what happened with <a href=\"blog.html#20260223-5-million-and-16-servers\">IOWarp and scientific computing</a>: a specialized domain where the tooling is powerful but the interfaces are hostile, and MCP shows up as the abstraction layer that makes agent mediation possible. DeFi's CLI and API sprawl — dozens of chains, each with their own RPC, wallet formats, and transaction semantics — is exactly the kind of complexity that benefits from a protocol-level agent interface. Expect more. The crypto builders move fast, and MCP just became a surface they can ship to.</p><p><em>Data sourced from the <a href=\"https://registry.modelcontextprotocol.io/\">MCP Registry</a> via <a href=\"./\">MCP Scorecard</a>. Trust scores computed from observable signals only.</em></p>",
    "publishers": [
      "io.github.debridge-finance",
      "io.github.Jrigada",
      "io.github.douglasborthwick-crypto"
    ]
  },
  {
    "slug": "20260223-registry-pulse",
    "title": "Registry Pulse: 123 New Servers in 24 Hours",
    "tag": "Pulse",
    "date": "2026-02-23",
    "summary": "The registry crossed 2,440 servers overnight. Two bulk publishers account for 72% of new entries. The shape of what's showing up matters more than the count.",
    "body": "<p>The MCP registry's growth has been steady for weeks — a dozen new servers here, twenty there. Yesterday it wasn't steady. <strong>123 new servers</strong> appeared in a single 24-hour scan, pushing the total from 2,317 to 2,440. Zero removed. A 5.3% jump, almost entirely driven by two publishers.</p><h3>Two Publishers, 89 Servers</h3><p><strong><a href=\"blog.html#20260223-i-am-the-law\">Ansvar</a></strong> (<a href=\"publisher.html#eu.ansvar\">eu.ansvar</a>) exploded from 6 servers to 76 overnight — one person, one template, 70 country-specific law servers. They're now the second-largest publisher in the entire registry. Their pitch: <em>\"you shouldn't need a law degree and 47 browser tabs. Ask Claude. Get the exact article. With context.\"</em></p><p><strong><a href=\"blog.html#20260223-5-million-and-16-servers\">IOWarp</a></strong> (<a href=\"publisher.html#io.github.iowarp\">io.github.iowarp</a>) brought 16 HPC-focused servers from a $5M NSF-funded research lab. Wrappers for HDF5, ADIOS, Slurm, Darshan, ParaView. They describe it as <em>\"one unified interface. 16 MCP servers. 150+ specialized tools. Built for research.\"</em></p><h3>By the Numbers</h3><table><thead><tr><th>Metric</th><th>Feb 22</th><th>Feb 23</th><th>Change</th></tr></thead><tbody><tr><td>Total servers</td><td>2,317</td><td>2,440</td><td>+123</td></tr><tr><td>With source repos</td><td>1,917</td><td>2,034</td><td>+117</td></tr><tr><td>With packages</td><td>1,519</td><td>1,634</td><td>+115</td></tr><tr><td>Average trust score</td><td>48.5</td><td>48.8</td><td>+0.3</td></tr></tbody></table><h3>Trust Distribution</h3><table><thead><tr><th>Tier</th><th>Count</th><th>Change</th></tr></thead><tbody><tr><td>High Trust (80–100)</td><td>34</td><td>—</td></tr><tr><td>Moderate Trust (60–79)</td><td>477</td><td>+22</td></tr><tr><td>Low Trust (40–59)</td><td>1,324</td><td>+94</td></tr><tr><td>Very Low Trust (20–39)</td><td>601</td><td>+7</td></tr><tr><td>Unknown/Suspicious (0–19)</td><td>4</td><td>—</td></tr></tbody></table><p>Most new entries land in Low Trust. Normal for fresh registrations — trust is earned over time through commits, releases, and community adoption.</p><h3>Notable New Entries</h3><ul><li><strong><a href=\"blog.html#20260223-the-server-you-cant-audit\">Exploit Intel</a></strong> — anonymous operators, no source code, wants your credentials. Score: <a href=\"publisher.html#com.exploit-intel\">29</a>.</li><li><strong><a href=\"blog.html#20260223-135x-smaller-than-playwright\">Charlotte</a></strong> — headless browser MCP returning 336 characters where Playwright returns 61,230. Score: <a href=\"publisher.html#io.github.TickTockBent\">61</a>.</li><li><strong><a href=\"blog.html#20260223-two-proxies-two-philosophies\">Two proxy servers</a></strong> — a commercial marketplace vs. an open-source context optimizer. The middleware layer is forming.</li><li><strong><a href=\"publisher.html#io.github.hebcal\">Hebcal</a></strong> — Jewish calendar data via MCP. Five contributors, repo age &gt;90 days. Score: <a href=\"publisher.html#io.github.hebcal\">63</a>.</li><li><strong><a href=\"publisher.html#io.github.mcpsbom\">SBOM-MCP</a></strong> — Software Bill of Materials for supply chain security. Score: <a href=\"publisher.html#io.github.mcpsbom\">41</a>.</li></ul><h3>What to Watch</h3><ol><li><strong>Mass-parameterized publishing is here.</strong> The registry has no concept of grouping templated clones from a single publisher.</li><li><strong>The publisher landscape is long-tail.</strong> 1,516 publishers have exactly one server. Only 32 have five or more.</li><li><strong>Scientific computing found MCP.</strong> IOWarp is the first serious academic play.</li></ol><p><em>Data sourced from the <a href=\"https://registry.modelcontextprotocol.io/\">MCP Registry</a> via <a href=\"./\">MCP Scorecard</a>. Trust scores computed from observable signals only.</em></p>",
    "publishers": [
      "eu.ansvar",
      "io.github.iowarp",
      "com.exploit-intel",
      "io.github.TickTockBent",
      "io.github.MCP-Hive",
      "io.github.karashiiro",
      "io.github.hebcal",
      "io.github.mcpsbom"
    ]
  },
  {
    "slug": "20260223-i-am-the-law",
    "title": "I Am the Law: One Man, 70 Countries, One Template",
    "tag": "Spotlight",
    "date": "2026-02-23",
    "summary": "A solo cybersecurity professional in Sweden used Claude to mass-publish 70 country-specific law MCP servers in a single month. The registry's first template-factory stress test.",
    "body": "<p>The <a href=\"publisher.html#eu.ansvar\"><code>eu.ansvar</code></a> namespace went from 6 servers to 76 overnight, making Ansvar the second-largest publisher in the MCP registry behind only <a href=\"publisher.html#ai.smithery\">Smithery</a> (214). Behind all 76 is one person: <strong>Jeffrey von Rotz</strong> (GitHub: <a href=\"https://github.com/Mortalus\">Mortalus</a>), a Dutch cybersecurity professional living in Sweden. His credentials read CISSP, OSCP, Volvo Group Global Cybersecurity Architect, Nordea Bank Security Testing Architect. His side project is <a href=\"https://ansvar.eu/\">Ansvar AI</a> — a compliance intelligence platform registered as Ansvar Systems AB in Sweden, launched January 2026.</p><p>His flagship EU compliance server puts the philosophy plainly:</p><blockquote><p>\"EU compliance is scattered across EUR-Lex PDFs, official journals, and regulatory sites... you shouldn't need a law degree and 47 browser tabs. Ask Claude. Get the exact article. With context.\"</p><cite>— <a href=\"https://github.com/Ansvar-Systems/EU_compliance_MCP\">EU_compliance_MCP README</a></cite></blockquote><p>The playbook: take one TypeScript MCP server template backed by SQLite FTS5, point it at a country's official legislation portal (EUR-Lex, Finlex, Lovdata, wetten.overheid.nl), ingest the corpus, register it. Repeat. Von Rotz used Claude Opus to scaffold each repo — the commit history shows <code>Co-Authored-By: Claude Opus 4.6</code> on the initial seeds. The acceleration tells the story: 2 repos on January 26th, then 4, then 7, then 19, then <strong>31 repos in a single day</strong> on February 21st. The flagship (112 commits, 45 stars, 2,528 articles across 49 EU regulations) is substantial. The Jamaican law server created in 8 commits on the same day as 30 others is thin.</p><p>The wider product pitch is ambitious — <em>\"27 specialized AI agents backed by 65+ open-source data sources\"</em> with managed threat modeling and on-prem Docker deployment for enterprise. The open-source law servers are the lead generation funnel. But this is also the first serious test of the MCP registry's growth model. Von Rotz isn't doing anything malicious — every server has source, a package, and real legislation data. But 70 templated clones each carrying an independent trust score isn't how anyone imagined the registry would scale. He's double-listed under both <code>eu.ansvar</code> and <code>io.github.Ansvar-Systems</code>, and <code>eu-regulations-mcp</code> appears 9 times. The registry has no deduplication, no template grouping, and no publisher-level trust. At 2,440 servers, that's cosmetic. At 24,000, it's a discoverability crisis. Von Rotz just showed everyone the playbook — the question is what happens when 50 people run it.</p><p>We plan to reach out to Jeffrey von Rotz for a future spotlight. If you're reading this, Jeffrey — we'd love to hear the full story.</p><p class=\"traceback\"><strong>Sources:</strong> Jeffrey von Rotz — <a href=\"https://github.com/Mortalus\">GitHub</a> · <a href=\"https://www.linkedin.com/in/jeffrey-von-rotz\">LinkedIn</a> · <a href=\"https://ansvar.eu/\">Ansvar AI</a> · Ansvar Systems AB (Org nr 559547-2225, Sweden) · <a href=\"https://github.com/Ansvar-Systems\">Ansvar-Systems GitHub org</a> · <a href=\"publisher.html#eu.ansvar\">Scorecard: eu.ansvar (76 servers)</a></p>",
    "publishers": [
      "eu.ansvar",
      "io.github.Ansvar-Systems"
    ]
  },
  {
    "slug": "20260223-5-million-and-16-servers",
    "title": "$5 Million and 16 Servers: When HPC Finds MCP",
    "tag": "Spotlight",
    "date": "2026-02-23",
    "summary": "An NSF-funded research lab at Illinois Tech just registered 16 MCP servers wrapping HDF5, Slurm, ADIOS, and ParaView. The scientific computing community is treating MCP as research infrastructure.",
    "body": "<p>Sixteen new MCP servers appeared today under <a href=\"publisher.html#io.github.iowarp\"><code>io.github.iowarp</code></a>: wrappers for HDF5, ADIOS, Darshan, Slurm, ParaView, Parquet, and more. These aren't weekend projects. They're the output of <strong>IOWarp</strong>, a $5 million NSF-funded research initiative (Awards <a href=\"https://www.nsf.gov/awardsearch/showAward?AWD_ID=2411318\">#2411318</a> and <a href=\"https://www.nsf.gov/awardsearch/showAward?AWD_ID=2411319\">#2411319</a>, 2024–2029) run by the <strong>Gnosis Research Center</strong> at the Illinois Institute of Technology. The principal investigator is <strong>Dr. Xian-He Sun</strong>, a University Distinguished Professor. The operational lead is <strong>Dr. Anthony Kougkas</strong> (<a href=\"https://akougkas.io/\">akougkas.io</a>), who holds a guest scientist position at Argonne National Laboratory. Their collaborator list spans Argonne, Lawrence Livermore, Sandia, Pacific Northwest National Laboratory, and The HDF Group.</p><blockquote><p>\"One unified interface. 16 MCP servers. 150+ specialized tools. Built for research.\"</p><cite>— <a href=\"https://github.com/iowarp/iowarp-mcps\">iowarp-mcps README</a></cite></blockquote><p>The pitch is that HPC has an interface problem. Scientists use HDF5, ADIOS, Darshan, and Slurm daily, but each tool has its own API, CLI, and data format. IOWarp's \"Context Layer for IO\" (CLIO) exposes them all through MCP so an AI agent can mediate — what their <a href=\"https://iowarp.ai/\">website</a> calls <em>\"the open-source platform that turns any AI agent into a science partner.\"</em> They claim 7.5x faster convergence in materials science workflows. The servers are BSD-3 licensed, published on PyPI as <code>iowarp-mcps</code>, and actively maintained — contributor Jaime Cernuda pushed 5 commits <em>today</em>. They scored 71–72 across the board, the highest-trust new entries in this batch.</p><p>This matters because it signals a class shift. Until now the MCP registry has been dominated by developer tools and SaaS wrappers. IOWarp is the first serious academic group treating MCP as <strong>scientific infrastructure</strong> — bridging the protocol into a world of national lab supercomputers and petabyte-scale simulations. The NSF grant title frames it explicitly: <em>\"Bending the I/O Fabric for Advancing AI-Infused Scientific Workflows.\"</em> If the pattern holds, expect MCP servers wrapping CERN ROOT, domain-specific simulation frameworks, and HPC job schedulers. The scientists aren't coming to MCP because it's trendy. They're coming because the abstraction layer they've wanted for 20 years finally showed up as an open protocol.</p><p class=\"traceback\"><strong>Sources:</strong> IOWarp — <a href=\"https://github.com/iowarp/\">GitHub</a> · <a href=\"https://iowarp.ai/\">iowarp.ai</a> · <a href=\"https://grc.iit.edu/\">Gnosis Research Center, IIT</a> · Dr. Anthony Kougkas — <a href=\"https://akougkas.io/\">site</a> · <a href=\"https://scholar.google.com/citations?user=hiNO0EEAAAAJ\">Google Scholar</a> · NSF Awards #2411318 / #2411319 · <a href=\"https://www.iit.edu/news/transforming-data-interaction-nsf-grant\">Illinois Tech announcement</a> · <a href=\"publisher.html#io.github.iowarp\">Scorecard: io.github.iowarp (16 servers)</a></p>",
    "publishers": [
      "io.github.iowarp"
    ]
  },
  {
    "slug": "20260223-the-server-you-cant-audit",
    "title": "The MCP Server You Can't Audit",
    "tag": "Spotlight",
    "date": "2026-02-23",
    "summary": "An anonymous collective published an exploit intelligence MCP server with no source code, no GitHub presence, and a Proton Mail contact. Score: 29.",
    "body": "<p><a href=\"publisher.html#com.exploit-intel\"><code>com.exploit-intel/eip-mcp</code></a> scored 29 — the lowest-trust new entry with a published package. It has no source code, no GitHub presence, and no named humans behind it. The contact is <code>exploit.intel@proton.me</code>. The MCP server wants your API credentials. You cannot see what it does with them.</p><p>The operators describe themselves on <a href=\"https://exploit-intel.com/about\">their about page</a>:</p><blockquote><p>\"We're a mixed crew of hackers, researchers, and defenders — some of us still remember the milw0rm days, others grew up on GitHub. We built EIP because we missed an exploit archive that was fast, trustworthy, and rich with context. We are a non-commercial group, we are not selling anything, and we do this because we genuinely love the field.\"</p><cite>— <a href=\"https://exploit-intel.com/about\">exploit-intel.com/about</a></cite></blockquote><p>The platform itself is polished: 334,701 CVEs tracked, 52,005 public exploits, aggregation from NVD, CISA KEV, ExploitDB, Metasploit, GitHub, and others. This isn't a throwaway. Someone put real work into a legitimate-looking exploit intelligence service, complete with API docs, a CLI tool, and now an MCP integration. They say they're <em>\"working toward\"</em> open-sourcing the backend. But \"working toward\" isn't \"did,\" and right now the trust model is broken at every level: anonymous operators, closed source, credential requests, and a domain that deals in exploit intelligence.</p><p>To be fair: an MCP server focused on exploit intelligence and security research has more reason than most to keep its internals private. Exposing source code for a tool that aggregates exploit data could itself be a security risk. That context matters. But it's not how we grade things at MCP Scorecard — our trust scores are computed from observable signals only, and closed-source with anonymous operators and credential requests is going to score low regardless of intent. The registry has no mechanism to distinguish well-intentioned security researchers who prefer anonymity from something adversarial, and neither can we.</p><p>We plan to reach out to the Exploit Intel team for a future spotlight — we'd like to learn more about the platform and the people behind it. If you're reading this: <a href=\"https://github.com/gigabrainobserver/mcp-scorecard/issues\">open an issue</a> or drop us a line.</p><p class=\"traceback\"><strong>Sources:</strong> Exploit Intelligence Platform — <a href=\"https://exploit-intel.com\">exploit-intel.com</a> · <a href=\"https://exploit-intel.com/about\">About page</a> · Contact: exploit.intel@proton.me · <a href=\"https://twitter.com/exploit_intel\">@exploit_intel</a> · No GitHub org or user found · No named individuals · <a href=\"publisher.html#com.exploit-intel\">Scorecard: com.exploit-intel (score 29)</a></p>",
    "publishers": [
      "com.exploit-intel"
    ]
  },
  {
    "slug": "20260223-135x-smaller-than-playwright",
    "title": "135x Smaller Than Playwright",
    "tag": "Spotlight",
    "date": "2026-02-23",
    "summary": "A solo developer in Virginia built a headless browser MCP server that returns 336 characters where Playwright returns 61,230. Progressive disclosure for the agent era.",
    "body": "<p>The browser MCP space just got its first real challenger. <strong>Charlotte</strong>, published 10 days ago by solo developer <strong>Wes S.</strong> (<a href=\"https://github.com/ticktockbent\">TickTockBent</a>, Virginia, USA, Clocktower and Associates), scored <a href=\"publisher.html#io.github.TickTockBent\">61</a> and already has 15 GitHub stars. The <a href=\"https://github.com/ticktockbent/charlotte\">README</a> frames the problem directly:</p><blockquote><p>\"Most browser MCP servers dump the entire accessibility tree on every call — a flat text blob that can exceed a million characters on content-heavy pages. Agents pay for all of it whether they need it or not.\"</p><cite>— <a href=\"https://github.com/ticktockbent/charlotte\">Charlotte README</a></cite></blockquote><p>Charlotte's answer is progressive disclosure. The <code>navigate</code> command returns landmarks, headings, and interactive element counts grouped by page region — enough to orient, not enough to overwhelm. The benchmarks are concrete: Wikipedia navigate returns 7,667 characters vs. Playwright's 1,040,636. Hacker News: 336 characters vs. 61,230. As the README puts it: <em>\"Playwright agents receive 61K+ characters every time they look at Hacker News, whether they're reading headlines or looking for a login button. Charlotte agents get 336 characters on arrival, call <code>find({ type: \"link\", text: \"login\" })</code> to get exactly what they need, and never pay for the rest.\"</em></p><p>It's MIT-licensed, published on npm as <code>@ticktockbent/charlotte</code>, with 30 tools across navigation, observation, interaction, session management, and dev mode. The <a href=\"https://charlotte-rose.vercel.app\">marketing site</a> was built by an AI agent running Charlotte itself — <em>\"An AI agent designed this entire website, wrote every component, and shipped it in a single session. It didn't need to. Charlotte gave it eyes.\"</em> Wes's other repos (<a href=\"https://github.com/ticktockbent/worktrunk\">worktrunk</a> for Git worktree management in parallel AI workflows, a Claude QoL extension) show someone building seriously in the agent tooling space.</p><p>The context-efficiency bet matters more than it looks. Every token of page structure stuffed into the context window is a token the model can't use for reasoning. Playwright's full-dump approach works for single-page tasks but scales poorly when agents browse multiple pages in sequence. Charlotte bets that progressive disclosure will win as agent workflows get more complex. At 10 days old it's too early to call, but the architecture is sound and the numbers are hard to argue with.</p><p class=\"traceback\"><strong>Sources:</strong> Wes S. (TickTockBent) — <a href=\"https://github.com/ticktockbent\">GitHub</a> · Charlotte — <a href=\"https://github.com/ticktockbent/charlotte\">repo</a> · <a href=\"https://www.npmjs.com/package/@ticktockbent/charlotte\">npm</a> · <a href=\"https://charlotte-rose.vercel.app\">site</a> · Clocktower and Associates, Virginia · <a href=\"publisher.html#io.github.TickTockBent\">Scorecard: io.github.TickTockBent (score 61)</a></p>",
    "publishers": [
      "io.github.TickTockBent"
    ]
  },
  {
    "slug": "20260223-two-proxies-two-philosophies",
    "title": "Two Proxies, Two Philosophies",
    "tag": "Trend",
    "date": "2026-02-23",
    "summary": "A Tel Aviv entrepreneur building a paid MCP marketplace and an FFXIV modder solving context bloat both shipped proxy servers in the same scan. The middleware layer is forming.",
    "body": "<p>Two MCP proxy servers appeared in the same scan. They solve different problems for different reasons, and together they outline the middleware layer forming between AI agents and MCP servers.</p><p><strong>MCP-Hive Proxy</strong> (<a href=\"publisher.html#io.github.MCP-Hive\">score: 59</a>) is a commercial marketplace gateway from <strong>Gary Weiss</strong> (<a href=\"https://github.com/namel\">namel</a>, Tel Aviv). Developers publish MCP servers to <a href=\"https://mcp-hive.com\">mcp-hive.com</a> with pricing; AI agents discover and call tools through the proxy; every call is tracked and billed. The pitch from the site:</p><blockquote><p>\"Welcome to MCP monetization done right. AI applications pay per request, providers earn per response. We handle the rest.\"</p><cite>— <a href=\"https://mcp-hive.com\">mcp-hive.com</a></cite></blockquote><p>Weiss posted a <a href=\"https://news.ycombinator.com/item?id=47110500\">Show HN</a> about it — zero comments, posted from a new account. The platform launches March 8, 2026. One-person org, no funding info, no customers yet. The proxy is Apache 2.0 licensed, but the marketplace it connects to is centralized and proprietary. This bets that MCP servers will become valuable enough to charge for, and that developers will accept a middleman.</p><p><strong>my-cool-proxy</strong> (<a href=\"publisher.html#io.github.karashiiro\">score: 59</a>, 9 stars) solves a purely technical problem. Built by <strong>Kara</strong> (<a href=\"https://github.com/karashiiro\">karashiiro</a>), a developer known in the Final Fantasy XIV modding community as the creator of Universalis, a crowdsourced market board API. The <a href=\"https://github.com/karashiiro/my-cool-proxy\">README</a> identifies the issue clearly:</p><blockquote><p>\"Tool descriptions bloat the context window. This is a problem with how most agents integrate with MCP. Rather than implementing abstractions that enable tools to be loaded as needed, most applications dump all MCP tools into the context at once.\"</p><cite>— <a href=\"https://github.com/karashiiro/my-cool-proxy\">my-cool-proxy README</a></cite></blockquote><p>Kara's proxy uses progressive disclosure — agents discover servers, then tools, then tool details incrementally. The novel bit: an embedded Lua interpreter lets agents compose multi-step workflows in a single <code>execute()</code> call, saving the context overhead of intermediate reasoning. MIT-licensed, published on npm, created December 2025 — two months older than MCP-Hive.</p><p>One proxy adds a business layer. The other removes a technical bottleneck. Neither knows the other exists. But both point to the same conclusion: the MCP ecosystem is developing a middleware tier. As the registry crosses 2,400 servers, the raw protocol isn't enough — something has to sit between agents and the growing catalog to handle discovery, routing, billing, or just keeping the context window from overflowing. Whether that layer ends up commercial, open-source, or both is one of the more interesting open questions in the ecosystem right now.</p><p class=\"traceback\"><strong>Sources:</strong> Gary Weiss — <a href=\"https://github.com/namel\">GitHub</a> · <a href=\"https://mcp-hive.com\">MCP-Hive</a> · <a href=\"https://news.ycombinator.com/item?id=47110500\">Show HN</a> · Kara — <a href=\"https://github.com/karashiiro\">GitHub</a> · <a href=\"https://github.com/karashiiro/my-cool-proxy\">my-cool-proxy repo</a> · <a href=\"https://www.npmjs.com/package/@karashiiro/my-cool-proxy\">npm</a> · <a href=\"publisher.html#io.github.MCP-Hive\">Scorecard: MCP-Hive</a> · <a href=\"publisher.html#io.github.karashiiro\">Scorecard: karashiiro</a></p>",
    "publishers": [
      "io.github.MCP-Hive",
      "io.github.karashiiro"
    ]
  }
]
